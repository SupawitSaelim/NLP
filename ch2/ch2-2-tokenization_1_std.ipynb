{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOCaRcOcVCAjkZngM2wIjRe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Tokenization**: nltk library\n","*   **nltk**: natural language toolkit\n","*   **punkt**: a module that includes pre-trained models for segmenting text into sentences and words.\n","*   **word_tokenize()**: to break down a string into tokens\n","\n","\n"],"metadata":{"id":"WCZrKVEBsua5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVseKKs3qvlg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721182473036,"user_tz":-420,"elapsed":4151,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"b98d3a98-65df-4d6c-b2e1-302161e59abf"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"markdown","source":["**Ex.1** Word tokenization"],"metadata":{"id":"Q9l1Od180lMz"}},{"cell_type":"code","source":["word_tokenize(\"Hi there!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_41LgG60WDj","executionInfo":{"status":"ok","timestamp":1721104441001,"user_tz":-420,"elapsed":420,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"c3225702-6e00-48ca-94c8-74ba986d4894"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hi', 'there', '!']"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**Ex.2** Word tokenization"],"metadata":{"id":"8bUC5U7w0sOB"}},{"cell_type":"code","source":["word_tokenize(\"I don't like Sam's shoes.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGIdwKu80t68","executionInfo":{"status":"ok","timestamp":1721104551314,"user_tz":-420,"elapsed":399,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"defc4a0b-48f5-4edd-940d-7d090bc71967"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I', 'do', \"n't\", 'like', 'Sam', \"'s\", 'shoes', '.']"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["\n","*   **sent_tokenize()**: to split a given text into individual sentences.\n","\n"],"metadata":{"id":"DoaoY03K2vsy"}},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize"],"metadata":{"id":"YhVLUFfP25UY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ex.3** Sentence tokenization"],"metadata":{"id":"kb8m4E6e2_WC"}},{"cell_type":"code","source":["text = \"Hello, world! This is a test. Let's see how it works.\"\n","sentences = sent_tokenize(text)\n","print(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUEeqzkj290R","executionInfo":{"status":"ok","timestamp":1721105188994,"user_tz":-420,"elapsed":454,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"413dc046-d63c-4ac4-ad42-a955a25ff017"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello, world!', 'This is a test.', \"Let's see how it works.\"]\n"]}]},{"cell_type":"markdown","source":["\n","*   **regexp_tokenize()**: to tokenize text based on a regular expression pattern.\n","\n"],"metadata":{"id":"ONPu53M13qJS"}},{"cell_type":"code","source":["from nltk.tokenize import regexp_tokenize"],"metadata":{"id":"b316dqqB3xKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ex.4** use regexp_tokenize"],"metadata":{"id":"R6s_bYJ233hZ"}},{"cell_type":"code","source":["text = \"Hello, world! This is a test.\"\n","\n","# Define a regular expression pattern to split the text by words and punctuation\n","# Matches any word character or matches any character that is not a word character \"\\w\" and not a whitespace character \"\\s\" (spaces, tabs, line breaks).\n","pattern = r'\\w+|[^\\w\\s]+'\n","\n","tokens = regexp_tokenize(text, pattern)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YdA9EbTd4DhQ","executionInfo":{"status":"ok","timestamp":1721106097664,"user_tz":-420,"elapsed":470,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"cf32a089-2c64-486d-fafb-39537b24e3ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', '.']\n"]}]},{"cell_type":"markdown","source":["\n","*   **TweetTokenizer()**: used specifically for tokenizing text, especially suited for content like tweets or text with similar characteristics found on social media platforms, allowing you to separate hashtags, mentions, emoticons,..\n"],"metadata":{"id":"9PAUS25lKwav"}},{"cell_type":"code","source":["from nltk.tokenize import TweetTokenizer"],"metadata":{"id":"ZLSyks3_LIap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ex.5** use TweetTokenizer"],"metadata":{"id":"KjAjAPpcLYSf"}},{"cell_type":"code","source":["tweet = \"This is a #test tweet! ðŸ˜Š Check out http://example.com @user #NLTK #Python\"\n","tokenizer = TweetTokenizer()\n","tokens = tokenizer.tokenize(tweet)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXfmJ9WbLeMy","executionInfo":{"status":"ok","timestamp":1721144118732,"user_tz":-420,"elapsed":584,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"7cc2a48f-f725-4da0-b038-24850c48a6ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['This', 'is', 'a', '#test', 'tweet', '!', 'ðŸ˜Š', 'Check', 'out', 'http://example.com', '@user', '#NLTK', '#Python']\n"]}]},{"cell_type":"markdown","source":["**Let's practice!**\n","\n","Word tokenization with NLTK\n","\n","*   Utilize **word_tokenize** and **sent_tokenize** from **nltk.tokenize** to tokenize both words and sentences from Python strings.\n","*   Import the **sent_tokenize** and **word_tokenize** functions from **nltk.tokenize**\n","\n","\n","\n"],"metadata":{"id":"VYNvi87kbhh6"}},{"cell_type":"code","source":["# Import necessary modules\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize"],"metadata":{"id":"8mTLACPDdE-h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","*   upload file \"scene_one.txt\"\n","*   Read txt file and keep in scene_one\n"],"metadata":{"id":"7dWapauPg1L5"}},{"cell_type":"code","source":["import io\n","from google.colab import files\n","\n","# Upload the file\n","uploaded = files.upload()\n","\n","# Read the content of the uploaded file\n","with io.StringIO(uploaded['scene_one.txt'].decode('utf-8')) as f:\n","    scene_one = f.read()\n","\n","# Display the content\n","print(scene_one)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":804},"id":"3fdWTsMvg0Pz","executionInfo":{"status":"ok","timestamp":1721183487011,"user_tz":-420,"elapsed":36443,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"288f29e6-0049-487a-9b60-1fe9c06b9069"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-dd0c59f8-c48d-46be-b3e9-fb53a0c83913\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-dd0c59f8-c48d-46be-b3e9-fb53a0c83913\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving scene_one.txt to scene_one.txt\n","SCENE 1: [wind] [clop clop clop] \r\n","KING ARTHUR: Whoa there!  [clop clop clop] \r\n","SOLDIER #1: Halt!  Who goes there?\r\n","ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\r\n","SOLDIER #1: Pull the other one!\r\n","ARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\r\n","SOLDIER #1: What?  Ridden on a horse?\r\n","ARTHUR: Yes!\r\n","SOLDIER #1: You're using coconuts!\r\n","ARTHUR: What?\r\n","SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\r\n","ARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\r\n","SOLDIER #1: Where'd you get the coconuts?\r\n","ARTHUR: We found them.\r\n","SOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\r\n","ARTHUR: What do you mean?\r\n","SOLDIER #1: Well, this is a temperate zone.\r\n","ARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\r\n","SOLDIER #1: Are you suggesting coconuts migrate?\r\n","ARTHUR: Not at all.  They could be carried.\r\n","SOLDIER #1: What?  A swallow carrying a coconut?\r\n","ARTHUR: It could grip it by the husk!\r\n","SOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\r\n","ARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\r\n","SOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\r\n","ARTHUR: Please!\r\n","SOLDIER #1: Am I right?\r\n","ARTHUR: I'm not interested!\r\n","SOLDIER #2: It could be carried by an African swallow!\r\n","SOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\r\n","SOLDIER #2: Oh, yeah, I agree with that.\r\n","ARTHUR: Will you ask your master if he wants to join my court at Camelot?!\r\n","SOLDIER #1: But then of course a-- African swallows are non-migratory.\r\n","SOLDIER #2: Oh, yeah...\r\n","SOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \r\n","SOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\r\n","SOLDIER #1: No, they'd have to have it on a line.\r\n","SOLDIER #2: Well, simple!  They'd just use a strand of creeper!\r\n","SOLDIER #1: What, held under the dorsal guiding feathers?\r\n","SOLDIER #2: Well, why not?\r\n","\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   Tokenize all sentences in **scene_one** using the **sent_tokenize()** function.\n","\n"],"metadata":{"id":"V8JargjqmFJw"}},{"cell_type":"code","source":["# Split scene_one into sentences: sentences\n","sentences =\n","print(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1QXeHsffZmr","executionInfo":{"status":"ok","timestamp":1721184646869,"user_tz":-420,"elapsed":407,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"2b9feff7-9d23-4a60-bdd6-862dbe96072e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['SCENE 1: [wind] [clop clop clop] \\r\\nKING ARTHUR: Whoa there!', '[clop clop clop] \\r\\nSOLDIER #1: Halt!', 'Who goes there?', 'ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.', 'King of the Britons, defeator of the Saxons, sovereign of all England!', 'SOLDIER #1: Pull the other one!', 'ARTHUR: I am, ...  and this is my trusty servant Patsy.', 'We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.', 'I must speak with your lord and master.', 'SOLDIER #1: What?', 'Ridden on a horse?', 'ARTHUR: Yes!', \"SOLDIER #1: You're using coconuts!\", 'ARTHUR: What?', \"SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\", 'ARTHUR: So?', \"We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\r\\nSOLDIER #1: Where'd you get the coconuts?\", 'ARTHUR: We found them.', 'SOLDIER #1: Found them?', 'In Mercea?', \"The coconut's tropical!\", 'ARTHUR: What do you mean?', 'SOLDIER #1: Well, this is a temperate zone.', 'ARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?', 'SOLDIER #1: Are you suggesting coconuts migrate?', 'ARTHUR: Not at all.', 'They could be carried.', 'SOLDIER #1: What?', 'A swallow carrying a coconut?', 'ARTHUR: It could grip it by the husk!', \"SOLDIER #1: It's not a question of where he grips it!\", \"It's a simple question of weight ratios!\", 'A five ounce bird could not carry a one pound coconut.', \"ARTHUR: Well, it doesn't matter.\", 'Will you go and tell your master that Arthur from the Court of Camelot is here.', 'SOLDIER #1: Listen.', 'In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?', 'ARTHUR: Please!', 'SOLDIER #1: Am I right?', \"ARTHUR: I'm not interested!\", 'SOLDIER #2: It could be carried by an African swallow!', 'SOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.', \"That's my point.\", 'SOLDIER #2: Oh, yeah, I agree with that.', 'ARTHUR: Will you ask your master if he wants to join my court at Camelot?!', 'SOLDIER #1: But then of course a-- African swallows are non-migratory.', 'SOLDIER #2: Oh, yeah...', \"SOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\r\\nSOLDIER #2: Wait a minute!\", 'Supposing two swallows carried it together?', \"SOLDIER #1: No, they'd have to have it on a line.\", 'SOLDIER #2: Well, simple!', \"They'd just use a strand of creeper!\", 'SOLDIER #1: What, held under the dorsal guiding feathers?', 'SOLDIER #2: Well, why not?']\n"]}]},{"cell_type":"markdown","source":["\n","\n","*  Tokenize the fourth sentence in **sentences**, which you can access as **sentences[3]**, using the **word_tokenize()** function.\n","\n"],"metadata":{"id":"MqWA2wlAmhZE"}},{"cell_type":"code","source":["# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n","tokenized_sent =\n","print(tokenized_sent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_k-yNpk_mqFk","executionInfo":{"status":"ok","timestamp":1721184764203,"user_tz":-420,"elapsed":402,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"fe6fda8b-2ea6-4636-ad43-95e9b94156dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['ARTHUR', ':', 'It', 'is', 'I', ',', 'Arthur', ',', 'son', 'of', 'Uther', 'Pendragon', ',', 'from', 'the', 'castle', 'of', 'Camelot', '.']\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   Find the unique tokens in the entire scene by using **word_tokenize()** on **scene_one** and then converting it into a set using **set()**.\n","\n"],"metadata":{"id":"ryBZzKvyqlYV"}},{"cell_type":"code","source":["# Make a set of unique tokens in the entire scene: unique_tokens\n","unique_tokens =\n","print(unique_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nd_svzz7q4oA","executionInfo":{"status":"ok","timestamp":1721185873563,"user_tz":-420,"elapsed":406,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"b479cf08-c989-42f1-c773-01ac4e58b62b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'am', 'if', '...', 'Wait', 'Well', 'That', 'court', 'Not', 'husk', 'will', 'back', 'to', 'suggesting', ':', 'that', 'in', 'my', 'Oh', 'strand', 'KING', 'Britons', 'must', 'martin', 'the', 'line', '#', 'master', 'seek', 'Yes', 'knights', 'but', 'trusty', 'you', 'times', \"n't\", 'Ridden', 'south', 'Supposing', 'house', 'beat', 'I', 'simple', 'all', 'SCENE', 'grips', 'Listen', 'What', 'Patsy', 'through', 'So', 'carrying', 'ARTHUR', \"'s\", '[', 'by', 'sovereign', 'coconuts', 'bangin', 'snows', \"'\", 'covered', 'In', 'coconut', 'tell', 'anyway', 'plover', 'horse', 'creeper', 'bird', 'ounce', 'may', 'carry', 'right', 'But', 'course', 'Pendragon', 'clop', 'there', 'Will', 'maintain', '?', '!', 'Uther', 'here', 'speak', 'your', 'an', 'SOLDIER', 'son', 'this', 'non-migratory', 'order', 'migrate', 'Halt', 'temperate', 'them', 'They', 'our', 'No', 'European', \"'d\", 'length', 'zone', 'needs', 'just', 'You', 'halves', 'yet', 'pound', 'from', 'dorsal', 'and', 'have', 'on', 'is', 'since', 'these', 'feathers', 'Where', 'warmer', 'be', '--', 'strangers', 'ridden', 'Found', 'got', 'ask', 'they', 'it', 'Arthur', 'using', \"'m\", 'maybe', 'does', 'King', 'Court', 'why', '.', 'where', 'sun', 'with', 'African', 'ratios', \"'re\", 'kingdom', 'who', 'Mercea', 'We', 'wings', 'swallows', 'use', '1', 'one', 'It', 'two', 'winter', 'minute', 'interested', 'join', 'go', 'matter', 'get', 'air-speed', 'or', 'Are', 'Am', 'defeator', 'together', 'Saxons', 'A', ',', 'he', 'second', 'climes', 'grip', 'wants', 'goes', 'carried', 'land', 'wind', 'yeah', 'held', 'search', \"'ve\", 'Please', 'do', 'tropical', 'forty-three', 'breadth', 'are', 'not', 'weight', 'swallow', \"'em\", '2', 'bring', 'of', 'question', 'then', 'at', 'velocity', 'under', 'fly', 'five', 'mean', 'other', 'Who', 'its', 'point', 'lord', 'Whoa', ']', 'castle', 'servant', 'a', 'guiding', 'could', 'empty', 'The', 'agree', 'found', 'Pull', 'England', 'every', 'me', 'Camelot'}\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   Use **re.search()** to search for the first occurrence of the word **\"coconuts\"** in **scene_one**. Store the result in match.\n","\n"],"metadata":{"id":"hoBaKz4dvRCB"}},{"cell_type":"code","source":["import re"],"metadata":{"id":"HFa5X7Ukv2h6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Search for the first occurrence of \"coconuts\" in scene_one: match\n","match =\n","# Print the start and end indexes of match\n","print(match.start(), match.end())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLexmoGKvt8B","executionInfo":{"status":"ok","timestamp":1721187196869,"user_tz":-420,"elapsed":415,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"c0773e2a-e0ea-4b1f-8cfb-6254622b8cd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["588 596\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   Write a regular expression called **pattern1** to find anything in square brackets.\n","\n"],"metadata":{"id":"4Kbxmk15wQJx"}},{"cell_type":"code","source":["# Write a regular expression to search for anything in square brackets: pattern1\n","pattern1 =\n","\n","# Use re.search to find the first text in square brackets\n","re."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYyCHokjwtLb","executionInfo":{"status":"ok","timestamp":1721187523087,"user_tz":-420,"elapsed":411,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"2a60d8f5-1009-49d5-cf5e-eb6f6403e555"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(9, 32), match='[wind] [clop clop clop]'>\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   Create a pattern to match the script notation (e.g. **Character**:), assigning the result to **pattern2**. Remember that you will want to match any words or spaces that precede the : (such as the space within **SOLDIER #1**:).\n","*   Use **re.match()** with your new pattern to find and print the script notation in the fourth line. The tokenized sentences are available in your namespace as **sentences**.\n","\n"],"metadata":{"id":"k040Qo2k3VaR"}},{"cell_type":"code","source":["# Find the script notation at the beginning of the fourth sentence and print it\n","pattern2 =\n","re."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0k3i1aj-3qho","executionInfo":{"status":"ok","timestamp":1721189204414,"user_tz":-420,"elapsed":414,"user":{"displayName":"Supaporn Simcharoen","userId":"08684475074805078308"}},"outputId":"c59fcf22-56eb-474e-c821-202d887119d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(0, 7), match='ARTHUR:'>\n"]}]}]}